## 2.1 从 `CPU` 联系到 `Java`
首先清楚：每个进程或线程发出操作请求后，最后会由 `CPU` 来分配时间片处理，处理时将操作数传递给 `CPU` , `CPU` 计算将其写回到“本地变量”中，这个本地变量通常存在于程序所谓的“栈”中，如果多次对这些本地变量进行操作，为了提升运算效率，它们有可能会被 `Cache` 到 `CPU` 的缓存中。 `CPU` 有寄存器、一级缓存、二级缓存，有的也有三级缓存， `CPU` 为什么有这么多组件呢？其实就是一个“就近原则”。  
  
打个比方，去某个地方办“几件事”，不会办完一件事情回家一趟，再坐车去办下一件事，因为时间开销大。如果发现办完一件事情后就在庞斑可以办下另一件事，则直接继续办理：如果发现有点累，则在外面小坐休息会，而不用回家休息。  
  
`CPU` 也可以一次做几件事情，所以它会有一个小的 `Cache` 区域，将这些内容暂时 `Cache` 住，这样距离处理器越近，操作的延迟就越小，整体效率自然就越快。
>一般来讲，一级缓存与 `CPU` 的延迟一般在 2~3ns 之间，二级缓存通常为 10~15ns ， 三级缓存为 20~30ns ，而内存通常会在 50ns 以上甚至更高。  
  
### 2.1.1 初识多核
在多核的 `Cache` 中（理解为多线程中的缓存策略），对某些数据 `Cache` 后，数据在“写入”和“读取”的时候必须满足一些规范，通常叫做“缓存一致性协议”。通过这种规范来实现架构，用以满足多个 `CPU` 对同一个变量修改时，相互之间都是知道的。不过，它并不能保证所有的数据都是这样的，因为这样做的开销是巨大的，所以在某些时候是允许不一致情况发生的（在分布式里，叫做最终一致性协议）。  
  
问题：我们编写的程序如何和 `CPU` 进行交互的？它是否会被 `Cache` ？是否存在并发问题？在可能的情况下，如何利用 `CPU` 来提高程序运行效率？  
  
编写 `Java` 程序时，大部分操作都是申请对象和操作对象，而对象实例的空间大部分存储在 `Java` 的堆（ `Heap` ）中，而 `Java` 的“栈”是中存储什么呢？  
  
`Java` 的“栈”更多的是通过 `JVM` 与 `OS` 一起管理的一块区域，写过 `C/C++` 程序的人应该知道，如果“不是”通过 `malloc` 、 `realloc` 、 `new` 等关键字申请的内存空间，那么作用域结束时自然释放，因为这部分的回收操作是由 `OS` 来管理和控制的。  
  
在 `Java` 程序中“栈空间”也是类似的，当程序的局部变量中使用基本类型时，它直接在“栈”上申请了一些空间，而当使用引用来引用对象时，这些引用的空间也位于“栈”上。（实际对象在堆中）。
>确切地说，在编译阶段， `Java` 就可以决定方法的“本地变量”（ `LocalVariable` ）的个数，因此在方法调用的时候，就可以直接分配一个本地变量的区域。这个空间是基于 `slot` 来分配的，每个 `slot` 占用 `32bit` ，就算是 `boolean` 也会占用这么宽，当然 `long` 、 `double` 会占用 2 个 `slot` 。这些 `slot` 可以被复用，也就是说，在方法体内部，如果某个局部变量是在循环或判定语句内部声明的，那么在退出这个区域后，对应的 `slot` 是可以被释放给它之后声明的局部变量使用的。

在程序运行过程中，会通过 `Java` 的虚指令来完成对 `Java` 虚拟机中对象和数据做一些操作。虚指令只是 `Java` 的指令，而不是最终指令，有它才会跨平台，它最终会在对应 `OS` 的虚拟机上被翻译为汇编指令来完成实际硬件的运行操作。

### 2.2.2 虚指令
源码：
```java
public static void main(String[] args) {
  int a = 1;
  int b = 2;
  int c = a + b;
}
```
将源码编译为 `class` 文件后，在字节码文件目录下使用： `javap -verbose .\Test.class` ，即可查看字节码文件。其中 `-verbose` 选项为输出常量信息。  
  
`JVM` 发出指令请求，由 `OS` 去完成具体工作， `JVM` 自身无法做计算工作。 `JVM` 内部对象的操作，例如字符串叠加，表面上也只是调用了一些数组拷贝。**也就是说， `JVM` 只关注自己的事情并组好，将其它的职责交给别人完成**。  
  
## 2.2 多核
多核 `CPU` 就像有多个计算机中心做事情。多个 `CPU` 要发挥最大效应就是不让某些人偷懒，自然就需要一些算法来协调和管理，让请求负载均衡（处处都有负载均衡啊）。比方说这个指令由哪个 `CPU` 来处理呢？同一份数据被多个 `CPU` 处理，并对其修改后，如何让其它的 `CPU` 知道呢？这中间产生各种各样的问题，算法也层出不穷，为了解决一个问题而将问题变得更加复杂，但是为了发展又不得不去做。在工作中也同样遇到系统不断变得复杂的过程，这是社会需求的进步，即使计算机部件也是同样的命运。  
  
当用户发起一个计算请求的时候，例如一个中断，这么多的 `CPU` 会干什么呢？这就要从人物的模型开始说起。起初，操作系统可能是不断地定时扫描各个部件看是否有指令来，有的话就处理，但是显然这种模式会很慢，因为“知道的时候往往都晚了”，这就是所谓的“非实时”。  
  
后来， `CPU` 有了“中断”模型，通过中断来完成调用，貌似实时性很强，但是某些部件发起中断频率非常高（例如鼠标移动，就在不断地发送指令）。此时对中断会有一个缓存区，由于 `CPU` 的处理速度非常快，可以在一瞬间处理大批量的请求，所以这种缓冲区是不错的设计思路（在许多设计中都会用到）。[点我详情了解中断机制](1)
  
一系列任务可能要做各种各样的事情，在通常情况下， `CPU` 的计算速度非常快，很快就可以完成指令。但是操作系统不希望 `CPU` 为一个“等待指令”或者是长期执行的任务使得自己“陷入困境”，比如一些 `I/O` 等待（网络 `I/O` 和磁盘 `I/O`），它中途基本都不参与，而是以事件注册的方式来实现回调，对于某些执行时间长的任务， `CPU` 可能会分配一些时间片来处理其它的任务。
>当 `CPU` 不断去切换任务处理的时候，又会有一种新的现象出现，那就是“上下文切换”。

当多个 `CPU` 在同一台计算机中出现的时候，会出现什么情况呢？是大家一起去抢指令？还是由一个 `CPU` 来分配指令？抑或是某些 `CPU` 专门管理某一块区域的指令？
  
`CPU` 是一个大家都要用的资源，那么就必须要有一个规范，而如何来规范呢？这没有明确的说法，只是大家的实现方法不同、架构不同，也许在不同的测试场景下效果会不同，调优的方法也有变化。这些会体现在计算机兼容性上， `CPU` 、内存、硬盘、主板等，在熟悉了具体厂商的实现机制后，相互配合兼容性就会做得更好。  
  
现在来说“大家一起去抢指令”，这种方式是不多见的，只是在某些系统的设计中有多进程模式，让多个进程监听同一个端口，当这个端口得到信号时，可能多个进程同时被唤醒的现象还是存在的，我们通常称之为“惊群”。（在监控中很多都会有这个情况，例如ZK一个节点被许多无意义的客户端监听）  
  
而“由一个 `CPU` 来分配指令”，这种方式也存在，那这样会不会让这个 `CPU` 很忙？也就是这个 `CPU` 会不会出现相对“飙”高的现象，尤其是有大量请求的时候？没错，它也有缺陷，只是通常情况下问题不会太大，而且它至少实现了调度，在有些时候可以划分下“领土”，使资源隔离是比较“靠谱”的。（类Master/Slave机制）  
  
那么我们按照板块来划分，每个板块有一个或多个 `CPU` 来管理对应的内存区域，是不是就合理了？也未必。首先，数据还需要和其它的部件通信，其它的部件资源是不是也是隔离的？要做到完全的物理划分是十分复杂的，通常意义上的物理划分只是相对底层的指令量、数据量的协调而已；其次，板块划分完后，就完全有可能出现热点问题（即某个 `CPU` 的任务非常重），如果需要热点问题我们应当如何处理呢？这个时候我们就要想其它的方法了。  

那到底哪种方法好呢？

其实没有好坏之分，只有场景的选择。

## 2.3 Cache line
前面提到“大家办事就近原则”，也就是一次可以办多件事情，或一件事情的多个步骤可以一次办完，相信这一点已经毋庸置疑。而 `Cache line` 是从另一个侧面来看问题，它好比是在办事情时需要携带许多材料，有些时候因为缺少材料要反复回家拿。例如，我们去办证大厅办理证件，每种证件都会有很多个步骤、很多分材料，这些我们都可以预先准备好，一次搞定，而不用因为缺少材料回家拿再办理。  
  
即， `Cache line` 将“连续的一段内存区域”进行 `Cache` ，不是每次就 `Cache` 一个内存单元，而是一系列内存单元。在计算机中，通常以连续 64 字节为基本单元进行 `Cache` 操作。那它与我们的 `Java` 程序到底有什么关系呢？

循环遍历二维数组 `int[][] a = new int[5][10]` ，有两种方法：先循环外层，在循环内层；先循环内层在循环内层。第一种的效率高。
>```java
int a[][] = new int[2][100];
int b[][] = new int[100][2];
// 两者内存开销的区别在第三章详说。
```
  
这个结论和 `Cache line` 有什么关系呢？因为 `Java` 数组在内存中分配是先分配第一维，然后再分配多个第二维自数字，也就是说， `a[0][x]` 和 `a[1][x]` 是位于两个不同数组上的，空间也自然不会在一起。  
  
单个数组的内存空间是连续的，当获取 `a[0][0]` 时， `Cache line` 操作通常会将 `a[0][0]` 先关的一些数组元素（如 `a[0][1]` 、 `a[0][2]`......`a[0][7]` ）全部都 `Cache` 到 `CPU
` 的缓存中，当使用第一种遍历方式来遍历时，这些连续的数据都只需要 `Cache` 一次，就可以遍历完成。
>`Cache line` 的目的是为了快速访问，当你对内存修改时，回写内存中并不是按照行进行的。

## 2.4 缓存一致性协议
在 `CPU` 上的实现就对应于多个 `CPU` 自己都会得到同一个内存单元的拷贝，当某个 `CPU` 修改它们的共享数据时，需要通知另一个 `CPU` 已经修改。  
  
内存单元有修改（`Modified`）、独占（`Exclusive`）、共享（`Shared`）、失效（`Invalid`）多种状态，多个 `CPU` 通过总线相互连接，




  
  
  
1: http://blog.csdn.net/phunxm/article/details/8952963
